{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30173,
     "status": "ok",
     "timestamp": 1747418217299,
     "user": {
      "displayName": "Jaroji Jaroji",
      "userId": "10588697490620152236"
     },
     "user_tz": -180
    },
    "id": "s5e-pKHj2LZP",
    "outputId": "f628605e-b190-4663-f4fb-24cea03c72aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "CrowdCounting directory found at: /content/drive/MyDrive/CrowdCounting/convnext\n",
      "Current working directory changed to: /content/drive/MyDrive/CrowdCounting/convnext\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Adjust the path if it's located in a subfolder\n",
    "project_path = \"/content/drive/MyDrive/CrowdCounting/convnext\"\n",
    "\n",
    "# Check if the path exists\n",
    "if os.path.exists(project_path):\n",
    "  print(f\"CrowdCounting directory found at: {project_path}\")\n",
    "  # Change the working directory to CrowdCounting\n",
    "  os.chdir(project_path)\n",
    "  print(f\"Current working directory changed to: {os.getcwd()}\")\n",
    "else:\n",
    "  print(f\"Error: CrowdCounting directory not found at {project_path}\")\n",
    "  print(\"Please ensure the path is correct and the directory exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3904,
     "status": "ok",
     "timestamp": 1747382067444,
     "user": {
      "displayName": "Jaroji Jaroji",
      "userId": "10588697490620152236"
     },
     "user_tz": -180
    },
    "id": "ODQLZXhneT0y",
    "outputId": "bba4380c-d5e3-4451-9fc6-53ae85ebcefd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All changes made in this colab session should now be visible in Drive.\n"
     ]
    }
   ],
   "source": [
    "# unmount the drive in case you want to unmount it\n",
    "# This will unmount the drive and flush any changes made in this session\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.flush_and_unmount()\n",
    "print('All changes made in this colab session should now be visible in Drive.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 97532,
     "status": "ok",
     "timestamp": 1747389254167,
     "user": {
      "displayName": "Jaroji Jaroji",
      "userId": "10588697490620152236"
     },
     "user_tz": -180
    },
    "id": "8_iwpQZfDMZT",
    "outputId": "834e2afe-d4eb-42de-88de-2794e5c22816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-msssim\n",
      "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pytorch-msssim) (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->pytorch-msssim)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->pytorch-msssim)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->pytorch-msssim)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->pytorch-msssim)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->pytorch-msssim)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->pytorch-msssim)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->pytorch-msssim)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->pytorch-msssim)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->pytorch-msssim)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->pytorch-msssim)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-msssim) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pytorch-msssim) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pytorch-msssim) (3.0.2)\n",
      "Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-msssim\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-msssim-1.0.0\n"
     ]
    }
   ],
   "source": [
    "# install msssim\n",
    "# This is a library for calculating the Multi-Scale Structural Similarity Index (MS-SSIM)\n",
    "!pip install pytorch-msssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24861103,
     "status": "ok",
     "timestamp": 1747414138709,
     "user": {
      "displayName": "Jaroji Jaroji",
      "userId": "10588697490620152236"
     },
     "user_tz": -180
    },
    "id": "KrgNq5roc3Nx",
    "outputId": "05df930b-1c03-4158-b938-d2fc0c40f5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n",
      "100% 109M/109M [00:00<00:00, 219MB/s] \n",
      "=> loading checkpoint 'shtb0-checkpoint.pth.tar'\n",
      "=> loaded checkpoint 'shtb0-checkpoint.pth.tar' (epoch 77)\n",
      "Epoch 77: 100% 1600/1600 [22:01<00:00,  1.21it/s, Loss=7.2088, AvgLoss=7.8057, Time=0.321s, Data=0.048s]\n",
      "begin test\n",
      " * MAE 22.955 \n",
      " * best MAE 22.955 \n",
      "Epoch 78: 100% 1600/1600 [08:48<00:00,  3.03it/s, Loss=1.8844, AvgLoss=7.7738, Time=0.326s, Data=0.035s]\n",
      "begin test\n",
      " * MAE 22.156 \n",
      " * best MAE 22.156 \n",
      "Epoch 79: 100% 1600/1600 [08:50<00:00,  3.02it/s, Loss=7.7892, AvgLoss=7.5591, Time=0.322s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 19.590 \n",
      " * best MAE 19.590 \n",
      "Epoch 80: 100% 1600/1600 [08:49<00:00,  3.02it/s, Loss=4.9545, AvgLoss=7.2860, Time=0.321s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 17.709 \n",
      " * best MAE 17.709 \n",
      "Epoch 81: 100% 1600/1600 [08:49<00:00,  3.02it/s, Loss=1.3015, AvgLoss=7.0128, Time=0.328s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 17.926 \n",
      " * best MAE 17.709 \n",
      "Epoch 82: 100% 1600/1600 [08:43<00:00,  3.06it/s, Loss=0.9698, AvgLoss=7.2634, Time=0.324s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 35.621 \n",
      " * best MAE 17.709 \n",
      "Epoch 83: 100% 1600/1600 [08:43<00:00,  3.06it/s, Loss=0.6008, AvgLoss=7.0792, Time=0.323s, Data=0.038s]\n",
      "begin test\n",
      " * MAE 22.589 \n",
      " * best MAE 17.709 \n",
      "Epoch 84: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=1.8889, AvgLoss=6.6460, Time=0.329s, Data=0.040s]\n",
      "begin test\n",
      " * MAE 17.626 \n",
      " * best MAE 17.626 \n",
      "Epoch 85: 100% 1600/1600 [08:50<00:00,  3.02it/s, Loss=1.5141, AvgLoss=6.4184, Time=0.327s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 17.258 \n",
      " * best MAE 17.258 \n",
      "Epoch 86: 100% 1600/1600 [08:47<00:00,  3.03it/s, Loss=1.2472, AvgLoss=6.3065, Time=0.326s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 19.271 \n",
      " * best MAE 17.258 \n",
      "Epoch 87: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=2.5203, AvgLoss=6.3903, Time=0.328s, Data=0.031s]\n",
      "begin test\n",
      " * MAE 17.263 \n",
      " * best MAE 17.258 \n",
      "Epoch 88: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=2.2696, AvgLoss=6.2343, Time=0.327s, Data=0.036s]\n",
      "begin test\n",
      " * MAE 15.944 \n",
      " * best MAE 15.944 \n",
      "Epoch 89: 100% 1600/1600 [08:47<00:00,  3.03it/s, Loss=2.9984, AvgLoss=6.1014, Time=0.325s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 33.513 \n",
      " * best MAE 15.944 \n",
      "Epoch 90: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=2.9256, AvgLoss=5.9090, Time=0.324s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 24.937 \n",
      " * best MAE 15.944 \n",
      "Epoch 91: 100% 1600/1600 [08:45<00:00,  3.05it/s, Loss=10.8659, AvgLoss=5.9464, Time=0.324s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 23.745 \n",
      " * best MAE 15.944 \n",
      "Epoch 92: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=4.4188, AvgLoss=5.8733, Time=0.325s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 15.671 \n",
      " * best MAE 15.671 \n",
      "Epoch 93: 100% 1600/1600 [08:50<00:00,  3.02it/s, Loss=5.0182, AvgLoss=5.7600, Time=0.323s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 22.927 \n",
      " * best MAE 15.671 \n",
      "Epoch 94: 100% 1600/1600 [08:43<00:00,  3.06it/s, Loss=0.6425, AvgLoss=5.7859, Time=0.326s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 18.749 \n",
      " * best MAE 15.671 \n",
      "Epoch 95: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=4.4633, AvgLoss=5.6382, Time=0.322s, Data=0.030s]\n",
      "begin test\n",
      " * MAE 39.685 \n",
      " * best MAE 15.671 \n",
      "Epoch 96: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=0.4145, AvgLoss=5.5718, Time=0.321s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 33.761 \n",
      " * best MAE 15.671 \n",
      "Epoch 97: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=0.9135, AvgLoss=5.7187, Time=0.333s, Data=0.036s]\n",
      "begin test\n",
      " * MAE 38.466 \n",
      " * best MAE 15.671 \n",
      "Epoch 98: 100% 1600/1600 [08:43<00:00,  3.06it/s, Loss=1.1413, AvgLoss=5.5503, Time=0.328s, Data=0.030s]\n",
      "begin test\n",
      " * MAE 45.942 \n",
      " * best MAE 15.671 \n",
      "Epoch 99: 100% 1600/1600 [08:42<00:00,  3.06it/s, Loss=21.4731, AvgLoss=5.2796, Time=0.323s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 33.174 \n",
      " * best MAE 15.671 \n",
      "Epoch 100: 100% 1600/1600 [08:42<00:00,  3.06it/s, Loss=0.8251, AvgLoss=4.9980, Time=0.324s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 27.200 \n",
      " * best MAE 15.671 \n",
      "Epoch 101: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=1.8197, AvgLoss=5.1291, Time=0.324s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 15.353 \n",
      " * best MAE 15.353 \n",
      "Epoch 102: 100% 1600/1600 [08:49<00:00,  3.02it/s, Loss=1.0780, AvgLoss=4.8779, Time=0.326s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 41.891 \n",
      " * best MAE 15.353 \n",
      "Epoch 103: 100% 1600/1600 [08:43<00:00,  3.06it/s, Loss=2.6523, AvgLoss=5.3196, Time=0.327s, Data=0.031s]\n",
      "begin test\n",
      " * MAE 26.417 \n",
      " * best MAE 15.353 \n",
      "Epoch 104: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=1.1468, AvgLoss=4.9489, Time=0.328s, Data=0.051s]\n",
      "begin test\n",
      " * MAE 36.236 \n",
      " * best MAE 15.353 \n",
      "Epoch 105: 100% 1600/1600 [08:43<00:00,  3.05it/s, Loss=14.7775, AvgLoss=4.6925, Time=0.323s, Data=0.032s]\n",
      "begin test\n",
      " * MAE 34.381 \n",
      " * best MAE 15.353 \n",
      "Epoch 106: 100% 1600/1600 [08:43<00:00,  3.06it/s, Loss=0.5638, AvgLoss=4.6775, Time=0.326s, Data=0.034s]\n",
      "begin test\n",
      " * MAE 31.353 \n",
      " * best MAE 15.353 \n",
      "Epoch 107: 100% 1600/1600 [08:43<00:00,  3.06it/s, Loss=1.6777, AvgLoss=4.7589, Time=0.313s, Data=0.041s]\n",
      "begin test\n",
      " * MAE 36.183 \n",
      " * best MAE 15.353 \n",
      "Epoch 108: 100% 1600/1600 [08:43<00:00,  3.05it/s, Loss=8.2828, AvgLoss=4.6315, Time=0.311s, Data=0.043s]\n",
      "begin test\n",
      " * MAE 30.367 \n",
      " * best MAE 15.353 \n",
      "Epoch 109: 100% 1600/1600 [08:42<00:00,  3.06it/s, Loss=1.4893, AvgLoss=4.5881, Time=0.325s, Data=0.036s]\n",
      "begin test\n",
      " * MAE 29.317 \n",
      " * best MAE 15.353 \n",
      "Epoch 110: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=1.8317, AvgLoss=4.4939, Time=0.325s, Data=0.032s]\n",
      "begin test\n",
      " * MAE 32.951 \n",
      " * best MAE 15.353 \n",
      "Epoch 111: 100% 1600/1600 [08:42<00:00,  3.06it/s, Loss=2.2865, AvgLoss=4.5991, Time=0.326s, Data=0.041s]\n",
      "begin test\n",
      " * MAE 29.433 \n",
      " * best MAE 15.353 \n",
      "Epoch 112: 100% 1600/1600 [08:43<00:00,  3.06it/s, Loss=1.0369, AvgLoss=4.5771, Time=0.324s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 32.215 \n",
      " * best MAE 15.353 \n",
      "Epoch 113: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=1.2527, AvgLoss=4.4753, Time=0.323s, Data=0.036s]\n",
      "begin test\n",
      " * MAE 36.259 \n",
      " * best MAE 15.353 \n",
      "Epoch 114: 100% 1600/1600 [08:43<00:00,  3.06it/s, Loss=10.7486, AvgLoss=4.3888, Time=0.325s, Data=0.035s]\n",
      "begin test\n",
      " * MAE 31.788 \n",
      " * best MAE 15.353 \n",
      "Epoch 115: 100% 1600/1600 [08:42<00:00,  3.06it/s, Loss=1.3599, AvgLoss=4.5542, Time=0.322s, Data=0.030s]\n",
      "begin test\n",
      " * MAE 39.023 \n",
      " * best MAE 15.353 \n",
      "Epoch 116: 100% 1600/1600 [08:43<00:00,  3.06it/s, Loss=2.9318, AvgLoss=4.3449, Time=0.336s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 51.166 \n",
      " * best MAE 15.353 \n",
      "Epoch 117: 100% 1600/1600 [08:42<00:00,  3.06it/s, Loss=0.8925, AvgLoss=4.4517, Time=0.323s, Data=0.030s]\n",
      "begin test\n",
      " * MAE 25.486 \n",
      " * best MAE 15.353 \n",
      "Epoch 118: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=0.8242, AvgLoss=4.1328, Time=0.322s, Data=0.045s]\n",
      "begin test\n",
      " * MAE 43.808 \n",
      " * best MAE 15.353 \n",
      "Epoch 119: 100% 1600/1600 [08:43<00:00,  3.06it/s, Loss=1.3354, AvgLoss=4.1639, Time=0.320s, Data=0.044s]\n",
      "begin test\n",
      " * MAE 24.401 \n",
      " * best MAE 15.353 \n",
      "Epoch 120: 100% 1600/1600 [08:42<00:00,  3.06it/s, Loss=26.4526, AvgLoss=4.0613, Time=0.325s, Data=0.050s]\n",
      "begin test\n",
      " * MAE 23.796 \n",
      " * best MAE 15.353 \n",
      "Epoch 121: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=2.5905, AvgLoss=4.2503, Time=0.336s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 19.729 \n",
      " * best MAE 15.353 \n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "!python train.py shtb_train.json shtb_val.json 0 shtb0- --pre shtb0-checkpoint.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9181132,
     "status": "ok",
     "timestamp": 1746697663329,
     "user": {
      "displayName": "Jaroji Jaroji",
      "userId": "10588697490620152236"
     },
     "user_tz": -180
    },
    "id": "nyVmbnxHh1tg",
    "outputId": "cd31e633-d779-4b6f-b72b-ba0ee908dd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'shtb1-model_best.pth.tar'\n",
      "=> loaded checkpoint 'shtb1-model_best.pth.tar' (epoch 13)\n",
      "Epoch 13: 100% 1600/1600 [08:33<00:00,  3.11it/s, Loss=1.8973, AvgLoss=4.2401, Time=0.329s, Data=0.044s]\n",
      "begin test\n",
      " * MAE 28.797 \n",
      " * best MAE 12.883 \n",
      "Epoch 14: 100% 1600/1600 [08:49<00:00,  3.02it/s, Loss=0.8018, AvgLoss=3.9503, Time=0.326s, Data=0.033s]\n",
      "begin test\n",
      " * MAE 34.674 \n",
      " * best MAE 12.883 \n",
      "Epoch 15: 100% 1600/1600 [08:50<00:00,  3.02it/s, Loss=0.6828, AvgLoss=4.2067, Time=0.318s, Data=0.041s]\n",
      "begin test\n",
      " * MAE 33.463 \n",
      " * best MAE 12.883 \n",
      "Epoch 16: 100% 1600/1600 [08:47<00:00,  3.03it/s, Loss=6.8198, AvgLoss=4.3240, Time=0.320s, Data=0.032s]\n",
      "begin test\n",
      " * MAE 28.831 \n",
      " * best MAE 12.883 \n",
      "Epoch 17: 100% 1600/1600 [08:46<00:00,  3.04it/s, Loss=3.5841, AvgLoss=3.8180, Time=0.352s, Data=0.040s]\n",
      "begin test\n",
      " * MAE 36.149 \n",
      " * best MAE 12.883 \n",
      "Epoch 18: 100% 1600/1600 [08:47<00:00,  3.04it/s, Loss=2.1006, AvgLoss=4.0379, Time=0.320s, Data=0.031s]\n",
      "begin test\n",
      " * MAE 21.504 \n",
      " * best MAE 12.883 \n",
      "Epoch 19: 100% 1600/1600 [08:46<00:00,  3.04it/s, Loss=0.6116, AvgLoss=3.8117, Time=0.338s, Data=0.031s]\n",
      "begin test\n",
      " * MAE 33.632 \n",
      " * best MAE 12.883 \n",
      "Epoch 20: 100% 1600/1600 [08:44<00:00,  3.05it/s, Loss=1.1806, AvgLoss=4.0623, Time=0.328s, Data=0.031s]\n",
      "begin test\n",
      " * MAE 31.122 \n",
      " * best MAE 12.883 \n",
      "Epoch 21: 100% 1600/1600 [08:46<00:00,  3.04it/s, Loss=1.2909, AvgLoss=3.7943, Time=0.319s, Data=0.031s]\n",
      "begin test\n",
      " * MAE 30.213 \n",
      " * best MAE 12.883 \n",
      "Epoch 22: 100% 1600/1600 [08:47<00:00,  3.04it/s, Loss=1.1028, AvgLoss=3.9728, Time=0.324s, Data=0.031s]\n",
      "begin test\n",
      " * MAE 35.403 \n",
      " * best MAE 12.883 \n",
      "Epoch 23: 100% 1600/1600 [08:45<00:00,  3.05it/s, Loss=76.1052, AvgLoss=3.7653, Time=0.326s, Data=0.031s]\n",
      "begin test\n",
      " * MAE 40.129 \n",
      " * best MAE 12.883 \n",
      "Epoch 24: 100% 1600/1600 [08:46<00:00,  3.04it/s, Loss=3.6490, AvgLoss=3.6974, Time=0.320s, Data=0.030s]\n",
      "begin test\n",
      " * MAE 32.455 \n",
      " * best MAE 12.883 \n",
      "Epoch 25: 100% 1600/1600 [08:46<00:00,  3.04it/s, Loss=0.8171, AvgLoss=3.5802, Time=0.330s, Data=0.032s]\n",
      "begin test\n",
      " * MAE 35.794 \n",
      " * best MAE 12.883 \n",
      "Epoch 26: 100% 1600/1600 [08:48<00:00,  3.03it/s, Loss=1.6707, AvgLoss=3.6711, Time=0.323s, Data=0.030s]\n",
      "begin test\n",
      " * MAE 31.772 \n",
      " * best MAE 12.883 \n",
      "Epoch 27: 100% 1600/1600 [08:48<00:00,  3.03it/s, Loss=10.5097, AvgLoss=3.5889, Time=0.327s, Data=0.034s]\n",
      "begin test\n",
      " * MAE 32.117 \n",
      " * best MAE 12.883 \n",
      "Epoch 28: 100% 1600/1600 [08:47<00:00,  3.03it/s, Loss=2.7270, AvgLoss=3.4428, Time=0.327s, Data=0.030s]\n",
      "begin test\n",
      " * MAE 22.453 \n",
      " * best MAE 12.883 \n",
      "Epoch 29: 100% 1600/1600 [08:47<00:00,  3.04it/s, Loss=0.5994, AvgLoss=3.7329, Time=0.320s, Data=0.033s]\n",
      "begin test\n",
      " * MAE 26.906 \n",
      " * best MAE 12.883 \n",
      "Epoch 30:  14% 227/1600 [01:19<07:58,  2.87it/s, Loss=2.1105, AvgLoss=3.2917, Time=0.324s, Data=0.032s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/CrowdCounting/convnext/train.py\", line 282, in <module>\n",
      "    main()        \n",
      "    ^^^^^^\n",
      "  File \"/content/drive/MyDrive/CrowdCounting/convnext/train.py\", line 118, in main\n",
      "    train(train_list, model, criterion, optimizer, epoch, ssim_loss)\n",
      "  File \"/content/drive/MyDrive/CrowdCounting/convnext/train.py\", line 174, in train\n",
      "    target = target.type(torch.FloatTensor).to(device)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py shtb_train.json shtb_val.json 0 shtb1- --pre shtb1-model_best.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2137693,
     "status": "ok",
     "timestamp": 1746537542972,
     "user": {
      "displayName": "Jaroji Jaroji",
      "userId": "10588697490620152236"
     },
     "user_tz": -180
    },
    "id": "s8PmuAl8ePXI",
    "outputId": "ccbf848e-c53b-4e64-b9f5-a7942f90365f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100% 1200/1200 [12:00<00:00,  1.66it/s, Loss=1020.1582, AvgLoss=319.3563, Time=0.213s, Data=0.016s]\n",
      "begin test\n",
      " * MAE 310.925 \n",
      " * best MAE 310.925 \n",
      "Epoch 1: 100% 1200/1200 [04:16<00:00,  4.69it/s, Loss=27.1794, AvgLoss=318.7345, Time=0.184s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 327.304 \n",
      " * best MAE 310.925 \n",
      "Epoch 2: 100% 1200/1200 [04:17<00:00,  4.66it/s, Loss=668.7253, AvgLoss=316.2365, Time=0.234s, Data=0.043s]\n",
      "begin test\n",
      " * MAE 314.280 \n",
      " * best MAE 310.925 \n",
      "Epoch 3: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=136.7488, AvgLoss=280.6803, Time=0.245s, Data=0.026s]\n",
      "begin test\n",
      " * MAE 159.424 \n",
      " * best MAE 159.424 \n",
      "Epoch 4: 100% 1200/1200 [04:22<00:00,  4.57it/s, Loss=164.5826, AvgLoss=238.0085, Time=0.214s, Data=0.027s]\n",
      "begin test\n",
      " * MAE 147.464 \n",
      " * best MAE 147.464 \n",
      "Epoch 5: 100% 1200/1200 [04:21<00:00,  4.59it/s, Loss=3.9858, AvgLoss=211.6719, Time=0.252s, Data=0.026s]\n",
      "begin test\n",
      " * MAE 111.248 \n",
      " * best MAE 111.248 \n",
      "Epoch 6: 100% 1200/1200 [04:21<00:00,  4.59it/s, Loss=43.3547, AvgLoss=197.6063, Time=0.081s, Data=0.016s]\n",
      "begin test\n",
      " * MAE 216.640 \n",
      " * best MAE 111.248 \n",
      "Epoch 7: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=21.5522, AvgLoss=192.3669, Time=0.208s, Data=0.040s]\n",
      "begin test\n",
      " * MAE 61.204 \n",
      " * best MAE 61.204 \n",
      "Epoch 8: 100% 1200/1200 [04:24<00:00,  4.53it/s, Loss=16.6682, AvgLoss=191.6439, Time=0.300s, Data=0.057s]\n",
      "begin test\n",
      " * MAE 76.894 \n",
      " * best MAE 61.204 \n",
      "Epoch 9: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=49.3699, AvgLoss=183.8168, Time=0.272s, Data=0.044s]\n",
      "begin test\n",
      " * MAE 143.735 \n",
      " * best MAE 61.204 \n",
      "Epoch 10: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=36.2095, AvgLoss=182.1379, Time=0.161s, Data=0.015s]\n",
      "begin test\n",
      " * MAE 147.566 \n",
      " * best MAE 61.204 \n",
      "Epoch 11: 100% 1200/1200 [04:17<00:00,  4.66it/s, Loss=120.2454, AvgLoss=180.8070, Time=0.114s, Data=0.017s]\n",
      "begin test\n",
      " * MAE 54.503 \n",
      " * best MAE 54.503 \n",
      "Epoch 12: 100% 1200/1200 [04:23<00:00,  4.56it/s, Loss=76.2537, AvgLoss=179.5549, Time=0.183s, Data=0.016s]\n",
      "begin test\n",
      " * MAE 150.012 \n",
      " * best MAE 54.503 \n",
      "Epoch 13: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=8.7944, AvgLoss=178.6499, Time=0.180s, Data=0.011s]\n",
      "begin test\n",
      " * MAE 53.188 \n",
      " * best MAE 53.188 \n",
      "Epoch 14: 100% 1200/1200 [04:24<00:00,  4.54it/s, Loss=37.4271, AvgLoss=175.6803, Time=0.263s, Data=0.032s]\n",
      "begin test\n",
      " * MAE 152.068 \n",
      " * best MAE 53.188 \n",
      "Epoch 15: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=48.9711, AvgLoss=176.5329, Time=0.282s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 52.287 \n",
      " * best MAE 52.287 \n",
      "Epoch 16: 100% 1200/1200 [04:21<00:00,  4.59it/s, Loss=17.4313, AvgLoss=173.8812, Time=0.302s, Data=0.032s]\n",
      "begin test\n",
      " * MAE 120.124 \n",
      " * best MAE 52.287 \n",
      "Epoch 17: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=44.2933, AvgLoss=173.0214, Time=0.174s, Data=0.016s]\n",
      "begin test\n",
      " * MAE 40.880 \n",
      " * best MAE 40.880 \n",
      "Epoch 18: 100% 1200/1200 [04:21<00:00,  4.59it/s, Loss=20.6894, AvgLoss=173.2471, Time=0.265s, Data=0.030s]\n",
      "begin test\n",
      " * MAE 60.635 \n",
      " * best MAE 40.880 \n",
      "Epoch 19: 100% 1200/1200 [04:17<00:00,  4.66it/s, Loss=950.4199, AvgLoss=171.3077, Time=0.226s, Data=0.026s]\n",
      "begin test\n",
      " * MAE 70.547 \n",
      " * best MAE 40.880 \n",
      "Epoch 20: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=112.2533, AvgLoss=171.4742, Time=0.209s, Data=0.033s]\n",
      "begin test\n",
      " * MAE 118.581 \n",
      " * best MAE 40.880 \n",
      "Epoch 21: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=248.6415, AvgLoss=170.1834, Time=0.148s, Data=0.011s]\n",
      "begin test\n",
      " * MAE 46.961 \n",
      " * best MAE 40.880 \n",
      "Epoch 22: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=16.8664, AvgLoss=169.4807, Time=0.181s, Data=0.022s]\n",
      "begin test\n",
      " * MAE 39.044 \n",
      " * best MAE 39.044 \n",
      "Epoch 23: 100% 1200/1200 [04:22<00:00,  4.56it/s, Loss=120.0761, AvgLoss=169.1839, Time=0.252s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 43.485 \n",
      " * best MAE 39.044 \n",
      "Epoch 24: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=16.8787, AvgLoss=170.5573, Time=0.178s, Data=0.017s]\n",
      "begin test\n",
      " * MAE 38.059 \n",
      " * best MAE 38.059 \n",
      "Epoch 25: 100% 1200/1200 [04:20<00:00,  4.60it/s, Loss=310.4105, AvgLoss=168.1877, Time=0.256s, Data=0.046s]\n",
      "begin test\n",
      " * MAE 89.909 \n",
      " * best MAE 38.059 \n",
      "Epoch 26: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=11.3197, AvgLoss=166.9628, Time=0.171s, Data=0.014s]\n",
      "begin test\n",
      " * MAE 37.125 \n",
      " * best MAE 37.125 \n",
      "Epoch 27: 100% 1200/1200 [04:21<00:00,  4.59it/s, Loss=21.3339, AvgLoss=167.5302, Time=0.146s, Data=0.015s]\n",
      "begin test\n",
      " * MAE 42.710 \n",
      " * best MAE 37.125 \n",
      "Epoch 28: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=40.1892, AvgLoss=165.9385, Time=0.175s, Data=0.023s]\n",
      "begin test\n",
      " * MAE 57.609 \n",
      " * best MAE 37.125 \n",
      "Epoch 29: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=185.5431, AvgLoss=165.4517, Time=0.250s, Data=0.038s]\n",
      "begin test\n",
      " * MAE 31.175 \n",
      " * best MAE 31.175 \n",
      "Epoch 30: 100% 1200/1200 [04:21<00:00,  4.58it/s, Loss=6.7844, AvgLoss=164.6809, Time=0.284s, Data=0.033s]\n",
      "begin test\n",
      " * MAE 37.552 \n",
      " * best MAE 31.175 \n",
      "Epoch 31: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=13.8638, AvgLoss=164.1509, Time=0.270s, Data=0.034s]\n",
      "begin test\n",
      " * MAE 31.703 \n",
      " * best MAE 31.175 \n",
      "Epoch 32: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=160.5379, AvgLoss=165.3632, Time=0.162s, Data=0.017s]\n",
      "begin test\n",
      " * MAE 42.101 \n",
      " * best MAE 31.175 \n",
      "Epoch 33: 100% 1200/1200 [04:17<00:00,  4.67it/s, Loss=297.7272, AvgLoss=165.1777, Time=0.248s, Data=0.047s]\n",
      "begin test\n",
      " * MAE 56.581 \n",
      " * best MAE 31.175 \n",
      "Epoch 34: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=0.9012, AvgLoss=166.7348, Time=0.055s, Data=0.020s]\n",
      "begin test\n",
      " * MAE 41.046 \n",
      " * best MAE 31.175 \n",
      "Epoch 35: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=0.4477, AvgLoss=163.6721, Time=0.134s, Data=0.011s]\n",
      "begin test\n",
      " * MAE 31.162 \n",
      " * best MAE 31.162 \n",
      "Epoch 36: 100% 1200/1200 [04:24<00:00,  4.54it/s, Loss=12.5354, AvgLoss=163.6872, Time=0.117s, Data=0.051s]\n",
      "begin test\n",
      " * MAE 55.164 \n",
      " * best MAE 31.162 \n",
      "Epoch 37: 100% 1200/1200 [04:16<00:00,  4.69it/s, Loss=1.3019, AvgLoss=162.2376, Time=0.269s, Data=0.036s]\n",
      "begin test\n",
      " * MAE 54.105 \n",
      " * best MAE 31.162 \n",
      "Epoch 38: 100% 1200/1200 [04:17<00:00,  4.67it/s, Loss=35.0875, AvgLoss=161.6447, Time=0.259s, Data=0.030s]\n",
      "begin test\n",
      " * MAE 49.712 \n",
      " * best MAE 31.162 \n",
      "Epoch 39: 100% 1200/1200 [04:17<00:00,  4.66it/s, Loss=54.3756, AvgLoss=161.2464, Time=0.283s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 40.334 \n",
      " * best MAE 31.162 \n",
      "Epoch 40: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=50.8879, AvgLoss=161.0479, Time=0.291s, Data=0.024s]\n",
      "begin test\n",
      " * MAE 39.725 \n",
      " * best MAE 31.162 \n",
      "Epoch 41: 100% 1200/1200 [04:16<00:00,  4.69it/s, Loss=32.2569, AvgLoss=161.7121, Time=0.284s, Data=0.024s]\n",
      "begin test\n",
      " * MAE 87.568 \n",
      " * best MAE 31.162 \n",
      "Epoch 42: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=36.5726, AvgLoss=161.0416, Time=0.167s, Data=0.022s]\n",
      "begin test\n",
      " * MAE 36.397 \n",
      " * best MAE 31.162 \n",
      "Epoch 43: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=112.2492, AvgLoss=160.5633, Time=0.240s, Data=0.023s]\n",
      "begin test\n",
      " * MAE 25.103 \n",
      " * best MAE 25.103 \n",
      "Epoch 44: 100% 1200/1200 [04:24<00:00,  4.54it/s, Loss=222.5306, AvgLoss=160.0906, Time=0.202s, Data=0.043s]\n",
      "begin test\n",
      " * MAE 31.710 \n",
      " * best MAE 25.103 \n",
      "Epoch 45: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=16.0798, AvgLoss=160.1428, Time=0.246s, Data=0.034s]\n",
      "begin test\n",
      " * MAE 38.334 \n",
      " * best MAE 25.103 \n",
      "Epoch 46: 100% 1200/1200 [04:17<00:00,  4.66it/s, Loss=57.9158, AvgLoss=159.2287, Time=0.314s, Data=0.059s]\n",
      "begin test\n",
      " * MAE 27.641 \n",
      " * best MAE 25.103 \n",
      "Epoch 47: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=10.0252, AvgLoss=159.1200, Time=0.260s, Data=0.027s]\n",
      "begin test\n",
      " * MAE 118.271 \n",
      " * best MAE 25.103 \n",
      "Epoch 48: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=10.1812, AvgLoss=159.4602, Time=0.230s, Data=0.032s]\n",
      "begin test\n",
      " * MAE 29.930 \n",
      " * best MAE 25.103 \n",
      "Epoch 49: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=2.6988, AvgLoss=160.1685, Time=0.211s, Data=0.027s]\n",
      "begin test\n",
      " * MAE 23.028 \n",
      " * best MAE 23.028 \n",
      "Epoch 50: 100% 1200/1200 [04:24<00:00,  4.54it/s, Loss=108.5779, AvgLoss=158.3594, Time=0.205s, Data=0.038s]\n",
      "begin test\n",
      " * MAE 50.040 \n",
      " * best MAE 23.028 \n",
      "Epoch 51: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=114.2533, AvgLoss=157.2997, Time=0.216s, Data=0.017s]\n",
      "begin test\n",
      " * MAE 59.751 \n",
      " * best MAE 23.028 \n",
      "Epoch 52: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=46.0936, AvgLoss=158.5234, Time=0.051s, Data=0.011s]\n",
      "begin test\n",
      " * MAE 33.131 \n",
      " * best MAE 23.028 \n",
      "Epoch 53: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=6.7572, AvgLoss=159.8059, Time=0.263s, Data=0.034s]\n",
      "begin test\n",
      " * MAE 79.878 \n",
      " * best MAE 23.028 \n",
      "Epoch 54: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=392.0319, AvgLoss=160.1127, Time=0.262s, Data=0.034s]\n",
      "begin test\n",
      " * MAE 254.247 \n",
      " * best MAE 23.028 \n",
      "Epoch 55: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=125.2907, AvgLoss=158.3880, Time=0.254s, Data=0.027s]\n",
      "begin test\n",
      " * MAE 34.596 \n",
      " * best MAE 23.028 \n",
      "Epoch 56: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=3.9639, AvgLoss=157.6619, Time=0.207s, Data=0.034s]\n",
      "begin test\n",
      " * MAE 39.367 \n",
      " * best MAE 23.028 \n",
      "Epoch 57: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=4.3494, AvgLoss=157.6396, Time=0.241s, Data=0.032s]\n",
      "begin test\n",
      " * MAE 52.837 \n",
      " * best MAE 23.028 \n",
      "Epoch 58: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=263.9935, AvgLoss=156.2839, Time=0.257s, Data=0.056s]\n",
      "begin test\n",
      " * MAE 58.460 \n",
      " * best MAE 23.028 \n",
      "Epoch 59: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=4.6880, AvgLoss=156.0699, Time=0.147s, Data=0.022s]\n",
      "begin test\n",
      " * MAE 23.425 \n",
      " * best MAE 23.028 \n",
      "Epoch 60: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=775.6636, AvgLoss=156.1314, Time=0.175s, Data=0.024s]\n",
      "begin test\n",
      " * MAE 26.337 \n",
      " * best MAE 23.028 \n",
      "Epoch 61: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=95.9315, AvgLoss=157.0131, Time=0.138s, Data=0.014s]\n",
      "begin test\n",
      " * MAE 35.504 \n",
      " * best MAE 23.028 \n",
      "Epoch 62: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=114.8641, AvgLoss=155.3818, Time=0.187s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 27.531 \n",
      " * best MAE 23.028 \n",
      "Epoch 63: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=1.9513, AvgLoss=156.2362, Time=0.259s, Data=0.052s]\n",
      "begin test\n",
      " * MAE 23.406 \n",
      " * best MAE 23.028 \n",
      "Epoch 64: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=39.3744, AvgLoss=155.7314, Time=0.178s, Data=0.016s]\n",
      "begin test\n",
      " * MAE 22.236 \n",
      " * best MAE 22.236 \n",
      "Epoch 65: 100% 1200/1200 [04:22<00:00,  4.56it/s, Loss=6.8375, AvgLoss=155.4172, Time=0.175s, Data=0.025s]\n",
      "begin test\n",
      " * MAE 28.521 \n",
      " * best MAE 22.236 \n",
      "Epoch 66: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=144.8956, AvgLoss=154.3393, Time=0.172s, Data=0.039s]\n",
      "begin test\n",
      " * MAE 35.931 \n",
      " * best MAE 22.236 \n",
      "Epoch 67: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=784.8914, AvgLoss=154.3309, Time=0.161s, Data=0.017s]\n",
      "begin test\n",
      " * MAE 25.285 \n",
      " * best MAE 22.236 \n",
      "Epoch 68: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=2.5388, AvgLoss=154.6746, Time=0.167s, Data=0.022s]\n",
      "begin test\n",
      " * MAE 41.730 \n",
      " * best MAE 22.236 \n",
      "Epoch 69: 100% 1200/1200 [04:16<00:00,  4.67it/s, Loss=5.6246, AvgLoss=154.0812, Time=0.262s, Data=0.033s]\n",
      "begin test\n",
      " * MAE 31.023 \n",
      " * best MAE 22.236 \n",
      "Epoch 70: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=31.6239, AvgLoss=154.4522, Time=0.311s, Data=0.038s]\n",
      "begin test\n",
      " * MAE 34.818 \n",
      " * best MAE 22.236 \n",
      "Epoch 71: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=79.1973, AvgLoss=154.0101, Time=0.181s, Data=0.019s]\n",
      "begin test\n",
      " * MAE 67.387 \n",
      " * best MAE 22.236 \n",
      "Epoch 72: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=73.7684, AvgLoss=153.3454, Time=0.126s, Data=0.012s]\n",
      "begin test\n",
      " * MAE 35.529 \n",
      " * best MAE 22.236 \n",
      "Epoch 73: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=23.2365, AvgLoss=153.7124, Time=0.163s, Data=0.012s]\n",
      "begin test\n",
      " * MAE 25.021 \n",
      " * best MAE 22.236 \n",
      "Epoch 74: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=16.6304, AvgLoss=153.2861, Time=0.166s, Data=0.023s]\n",
      "begin test\n",
      " * MAE 27.122 \n",
      " * best MAE 22.236 \n",
      "Epoch 75: 100% 1200/1200 [04:13<00:00,  4.73it/s, Loss=6.8464, AvgLoss=153.0937, Time=0.257s, Data=0.032s]\n",
      "begin test\n",
      " * MAE 28.127 \n",
      " * best MAE 22.236 \n",
      "Epoch 76: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=16.7109, AvgLoss=152.9430, Time=0.159s, Data=0.015s]\n",
      "begin test\n",
      " * MAE 23.981 \n",
      " * best MAE 22.236 \n",
      "Epoch 77: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=92.0610, AvgLoss=152.4255, Time=0.247s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 35.583 \n",
      " * best MAE 22.236 \n",
      "Epoch 78: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=23.8283, AvgLoss=152.5282, Time=0.224s, Data=0.022s]\n",
      "begin test\n",
      " * MAE 64.160 \n",
      " * best MAE 22.236 \n",
      "Epoch 79: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=12.0284, AvgLoss=153.7671, Time=0.141s, Data=0.013s]\n",
      "begin test\n",
      " * MAE 23.982 \n",
      " * best MAE 22.236 \n",
      "Epoch 80: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=17.5202, AvgLoss=152.4373, Time=0.146s, Data=0.010s]\n",
      "begin test\n",
      " * MAE 20.907 \n",
      " * best MAE 20.907 \n",
      "Epoch 81: 100% 1200/1200 [04:21<00:00,  4.60it/s, Loss=17.6027, AvgLoss=152.4604, Time=0.090s, Data=0.012s]\n",
      "begin test\n",
      " * MAE 40.107 \n",
      " * best MAE 20.907 \n",
      "Epoch 82: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=140.6189, AvgLoss=152.1332, Time=0.275s, Data=0.027s]\n",
      "begin test\n",
      " * MAE 30.324 \n",
      " * best MAE 20.907 \n",
      "Epoch 83: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=160.1365, AvgLoss=152.1552, Time=0.109s, Data=0.027s]\n",
      "begin test\n",
      " * MAE 18.208 \n",
      " * best MAE 18.208 \n",
      "Epoch 84: 100% 1200/1200 [04:19<00:00,  4.62it/s, Loss=532.2729, AvgLoss=151.9224, Time=0.262s, Data=0.031s]\n",
      "begin test\n",
      " * MAE 23.430 \n",
      " * best MAE 18.208 \n",
      "Epoch 85: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=36.7002, AvgLoss=151.6548, Time=0.188s, Data=0.014s]\n",
      "begin test\n",
      " * MAE 87.958 \n",
      " * best MAE 18.208 \n",
      "Epoch 86: 100% 1200/1200 [04:16<00:00,  4.69it/s, Loss=16.3001, AvgLoss=151.7197, Time=0.078s, Data=0.022s]\n",
      "begin test\n",
      " * MAE 34.026 \n",
      " * best MAE 18.208 \n",
      "Epoch 87: 100% 1200/1200 [04:15<00:00,  4.71it/s, Loss=350.3304, AvgLoss=151.9726, Time=0.103s, Data=0.015s]\n",
      "begin test\n",
      " * MAE 26.465 \n",
      " * best MAE 18.208 \n",
      "Epoch 88: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=177.2865, AvgLoss=152.6802, Time=0.230s, Data=0.020s]\n",
      "begin test\n",
      " * MAE 23.126 \n",
      " * best MAE 18.208 \n",
      "Epoch 89: 100% 1200/1200 [04:16<00:00,  4.68it/s, Loss=100.5521, AvgLoss=151.1472, Time=0.226s, Data=0.020s]\n",
      "begin test\n",
      " * MAE 18.742 \n",
      " * best MAE 18.208 \n",
      "Epoch 90: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=0.4044, AvgLoss=151.5560, Time=0.198s, Data=0.020s]\n",
      "begin test\n",
      " * MAE 21.661 \n",
      " * best MAE 18.208 \n",
      "Epoch 91: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=1419.9683, AvgLoss=152.1214, Time=0.262s, Data=0.027s]\n",
      "begin test\n",
      " * MAE 24.281 \n",
      " * best MAE 18.208 \n",
      "Epoch 92: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=1395.2025, AvgLoss=151.2241, Time=0.273s, Data=0.022s]\n",
      "begin test\n",
      " * MAE 29.298 \n",
      " * best MAE 18.208 \n",
      "Epoch 93: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=23.7454, AvgLoss=151.0517, Time=0.221s, Data=0.022s]\n",
      "begin test\n",
      " * MAE 28.261 \n",
      " * best MAE 18.208 \n",
      "Epoch 94: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=15.9956, AvgLoss=151.0690, Time=0.211s, Data=0.035s]\n",
      "begin test\n",
      " * MAE 21.829 \n",
      " * best MAE 18.208 \n",
      "Epoch 95: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=672.1039, AvgLoss=150.8628, Time=0.268s, Data=0.034s]\n",
      "begin test\n",
      " * MAE 25.587 \n",
      " * best MAE 18.208 \n",
      "Epoch 96: 100% 1200/1200 [04:14<00:00,  4.71it/s, Loss=68.9096, AvgLoss=150.4028, Time=0.237s, Data=0.024s]\n",
      "begin test\n",
      " * MAE 16.534 \n",
      " * best MAE 16.534 \n",
      "Epoch 97: 100% 1200/1200 [04:21<00:00,  4.59it/s, Loss=311.4078, AvgLoss=151.3053, Time=0.222s, Data=0.023s]\n",
      "begin test\n",
      " * MAE 22.793 \n",
      " * best MAE 16.534 \n",
      "Epoch 98: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=17.5262, AvgLoss=150.1050, Time=0.155s, Data=0.015s]\n",
      "begin test\n",
      " * MAE 21.113 \n",
      " * best MAE 16.534 \n",
      "Epoch 99: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=23.9547, AvgLoss=150.0230, Time=0.220s, Data=0.024s]\n",
      "begin test\n",
      " * MAE 21.115 \n",
      " * best MAE 16.534 \n",
      "Epoch 100: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=61.7871, AvgLoss=150.3401, Time=0.239s, Data=0.043s]\n",
      "begin test\n",
      " * MAE 37.332 \n",
      " * best MAE 16.534 \n",
      "Epoch 101:   4% 47/1200 [00:09<03:50,  5.00it/s, Loss=1216.4194, AvgLoss=170.1901, Time=0.267s, Data=0.030s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/CrowdCounting/convnext/train.py\", line 268, in <module>\n",
      "  File \"/content/drive/MyDrive/CrowdCounting/convnext/train.py\", line 102, in main\n",
      "    train(train_list, model, criterion, optimizer, epoch)\n",
      "  File \"/content/drive/MyDrive/CrowdCounting/convnext/train.py\", line 154, in train\n",
      "    img = img.to(device)\n",
      "          ^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py shta_train.json shta_val.json 0 shta0-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3875420,
     "status": "ok",
     "timestamp": 1746637156405,
     "user": {
      "displayName": "Jaroji Jaroji",
      "userId": "10588697490620152236"
     },
     "user_tz": -180
    },
    "id": "z2E8NQ64Wolg",
    "outputId": "8ee094d3-eb57-488a-c652-1970a256bd9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'shtA1-model_best.pth.tar'\n",
      "=> loaded checkpoint 'shtA1-model_best.pth.tar' (epoch 74)\n",
      "Epoch 74: 100% 1200/1200 [04:10<00:00,  4.79it/s, Loss=71.3218, AvgLoss=144.3719, Time=0.169s, Data=0.024s]\n",
      "begin test\n",
      " * MAE 14.807 \n",
      " * best MAE 14.279 \n",
      "Epoch 75: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=147.8352, AvgLoss=144.3262, Time=0.161s, Data=0.015s]\n",
      "begin test\n",
      " * MAE 15.051 \n",
      " * best MAE 14.279 \n",
      "Epoch 76: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=20.0929, AvgLoss=144.3523, Time=0.155s, Data=0.013s]\n",
      "begin test\n",
      " * MAE 15.102 \n",
      " * best MAE 14.279 \n",
      "Epoch 77: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=23.0658, AvgLoss=144.3200, Time=0.241s, Data=0.025s]\n",
      "begin test\n",
      " * MAE 15.489 \n",
      " * best MAE 14.279 \n",
      "Epoch 78: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=203.4712, AvgLoss=144.2168, Time=0.265s, Data=0.034s]\n",
      "begin test\n",
      " * MAE 15.083 \n",
      " * best MAE 14.279 \n",
      "Epoch 79: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=48.1268, AvgLoss=144.2460, Time=0.112s, Data=0.017s]\n",
      "begin test\n",
      " * MAE 15.099 \n",
      " * best MAE 14.279 \n",
      "Epoch 80: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=10.9900, AvgLoss=144.2676, Time=0.219s, Data=0.035s]\n",
      "begin test\n",
      " * MAE 14.944 \n",
      " * best MAE 14.279 \n",
      "Epoch 81: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=43.0000, AvgLoss=144.3947, Time=0.180s, Data=0.030s]\n",
      "begin test\n",
      " * MAE 14.730 \n",
      " * best MAE 14.279 \n",
      "Epoch 82: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=96.4001, AvgLoss=144.4248, Time=0.170s, Data=0.012s]\n",
      "begin test\n",
      " * MAE 14.928 \n",
      " * best MAE 14.279 \n",
      "Epoch 83: 100% 1200/1200 [04:14<00:00,  4.71it/s, Loss=61.0214, AvgLoss=144.2655, Time=0.235s, Data=0.036s]\n",
      "begin test\n",
      " * MAE 14.957 \n",
      " * best MAE 14.279 \n",
      "Epoch 84: 100% 1200/1200 [04:13<00:00,  4.73it/s, Loss=42.3696, AvgLoss=144.3533, Time=0.280s, Data=0.031s]\n",
      "begin test\n",
      " * MAE 14.976 \n",
      " * best MAE 14.279 \n",
      "Epoch 85: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=11.1172, AvgLoss=144.2309, Time=0.190s, Data=0.037s]\n",
      "begin test\n",
      " * MAE 14.787 \n",
      " * best MAE 14.279 \n",
      "Epoch 86: 100% 1200/1200 [04:13<00:00,  4.73it/s, Loss=1197.3667, AvgLoss=144.2981, Time=0.188s, Data=0.031s]\n",
      "begin test\n",
      " * MAE 14.914 \n",
      " * best MAE 14.279 \n",
      "Epoch 87: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=3.7382, AvgLoss=144.1918, Time=0.177s, Data=0.013s]\n",
      "begin test\n",
      " * MAE 15.013 \n",
      " * best MAE 14.279 \n",
      "Epoch 88: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=552.8570, AvgLoss=144.3453, Time=0.267s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 15.356 \n",
      " * best MAE 14.279 \n",
      "Epoch 89: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=50.3240, AvgLoss=144.2407, Time=0.189s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 15.178 \n",
      " * best MAE 14.279 \n",
      "Epoch 90: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=3.8345, AvgLoss=144.2723, Time=0.188s, Data=0.020s]\n",
      "begin test\n",
      " * MAE 14.942 \n",
      " * best MAE 14.279 \n",
      "Epoch 91: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=174.4743, AvgLoss=144.4633, Time=0.241s, Data=0.023s]\n",
      "begin test\n",
      " * MAE 15.312 \n",
      " * best MAE 14.279 \n",
      "Epoch 92: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=4.7688, AvgLoss=144.2252, Time=0.256s, Data=0.025s]\n",
      "begin test\n",
      " * MAE 14.978 \n",
      " * best MAE 14.279 \n",
      "Epoch 93: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=7.5479, AvgLoss=144.1797, Time=0.133s, Data=0.018s]\n",
      "begin test\n",
      " * MAE 14.746 \n",
      " * best MAE 14.279 \n",
      "Epoch 94: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=8.8189, AvgLoss=144.2610, Time=0.254s, Data=0.028s]\n",
      "begin test\n",
      " * MAE 14.918 \n",
      " * best MAE 14.279 \n",
      "Epoch 95: 100% 1200/1200 [04:13<00:00,  4.73it/s, Loss=8.6782, AvgLoss=144.2454, Time=0.282s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 15.084 \n",
      " * best MAE 14.279 \n",
      "Epoch 96: 100% 1200/1200 [04:13<00:00,  4.74it/s, Loss=3.3301, AvgLoss=144.2355, Time=0.274s, Data=0.029s]\n",
      "begin test\n",
      " * MAE 14.931 \n",
      " * best MAE 14.279 \n",
      "Epoch 97: 100% 1200/1200 [04:14<00:00,  4.72it/s, Loss=76.2237, AvgLoss=144.3066, Time=0.261s, Data=0.039s]\n",
      "begin test\n",
      " * MAE 15.375 \n",
      " * best MAE 14.279 \n",
      "Epoch 98: 100% 1200/1200 [04:15<00:00,  4.69it/s, Loss=9.4780, AvgLoss=144.1851, Time=0.238s, Data=0.024s]\n",
      "begin test\n",
      " * MAE 15.309 \n",
      " * best MAE 14.279 \n",
      "Epoch 99: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=104.9698, AvgLoss=144.2454, Time=0.215s, Data=0.021s]\n",
      "begin test\n",
      " * MAE 15.213 \n",
      " * best MAE 14.279 \n",
      "Epoch 100: 100% 1200/1200 [04:16<00:00,  4.69it/s, Loss=41.5351, AvgLoss=144.2383, Time=0.072s, Data=0.009s]\n",
      "begin test\n",
      " * MAE 15.139 \n",
      " * best MAE 14.279 \n",
      "Epoch 101: 100% 1200/1200 [04:15<00:00,  4.70it/s, Loss=9.9575, AvgLoss=144.3359, Time=0.251s, Data=0.027s]\n",
      "begin test\n",
      " * MAE 15.375 \n",
      " * best MAE 14.279 \n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "!python train.py shta_train.json shta_val.json 0 shta1- --pre shta1-model_best.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1uqGdHDAEohyU77AdePuXtC5hEr9boEwZ"
    },
    "executionInfo": {
     "elapsed": 394697,
     "status": "ok",
     "timestamp": 1747418637116,
     "user": {
      "displayName": "Jaroji Jaroji",
      "userId": "10588697490620152236"
     },
     "user_tz": -180
    },
    "id": "ajvSP-j-D0Vq",
    "outputId": "d5a0f09f-f8fb-445c-c1b7-90d39f50731e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In[1]: Imports dan konfigurasi\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import importlib\n",
    "import dataset  # pertama kali import\n",
    "importlib.reload(dataset)\n",
    "from dataset import listDataset\n",
    "import model\n",
    "importlib.reload(model)\n",
    "from model import ConvNeXt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import cv2\n",
    "\n",
    "# --- Konfigurasi ---\n",
    "TRAIN_JSON       = 'part_B_test.json'       # Ganti sesuai path Anda\n",
    "CHECKPOINT_PATH  = 'shtb0-model_best.pth.tar'  # Ganti sesuai path checkpoint\n",
    "DEVICE           = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE       = 1\n",
    "NUM_WORKERS      = 2\n",
    "MAX_BATCHES      = None     # Kalau None → evaluasi penuh. Atau set integer untuk debug cepat\n",
    "PLOT_SAMPLES     = 6        # Berapa contoh yang diplot\n",
    "\n",
    "# In[2]: Dataset and DataLoader Setup\n",
    "def get_dataloader(json_path, batch_size, num_workers):\n",
    "    with open(json_path, 'r') as f:\n",
    "        img_list = json.load(f)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = listDataset(img_list, transform=transform, train=False)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "train_loader = get_dataloader(TRAIN_JSON, BATCH_SIZE, NUM_WORKERS)\n",
    "\n",
    "# In[3]: Load Model\n",
    "def load_model(checkpoint_path, device):\n",
    "    model = ConvNeXt().to(device)\n",
    "    ckpt  = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_model(CHECKPOINT_PATH, DEVICE)\n",
    "\n",
    "# In[5]: Inverse Normalization Utility\n",
    "def denormalize(tensor):\n",
    "    inv_norm = transforms.Normalize(\n",
    "        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "        std=[1/0.229,    1/0.224,    1/0.225]\n",
    "    )\n",
    "    return inv_norm(tensor)\n",
    "\n",
    "# In[6]: Plot Samples as Subplots\n",
    "def plot_density_examples(loader, model, device, num_samples=3):\n",
    "    for idx, (imgs, targets) in enumerate(loader):\n",
    "        if idx >= num_samples:\n",
    "            break\n",
    "        img_t  = imgs[0]\n",
    "        gt_map = targets[0].squeeze(0).cpu().numpy()\n",
    "        with torch.no_grad():\n",
    "            pred_map = model(imgs.to(device))[0].squeeze(0).cpu().numpy()\n",
    "\n",
    "        # Convert image back to uint8 RGB\n",
    "        img_vis = denormalize(img_t).permute(1,2,0).cpu().numpy()\n",
    "        img_vis = np.clip(img_vis * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # Create subplots (1 row, 3 columns)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "        axes[0].imshow(img_vis)\n",
    "        axes[0].axis('off')\n",
    "        axes[0].set_title(f\"Original #{idx}\")\n",
    "\n",
    "        axes[1].imshow(gt_map, interpolation='nearest')\n",
    "        axes[1].axis('off')\n",
    "        axes[1].set_title(f\"GT Density — Count: {gt_map.sum():.1f}\")\n",
    "\n",
    "        axes[2].imshow(pred_map, interpolation='nearest')\n",
    "        axes[2].axis('off')\n",
    "        axes[2].set_title(f\"Pred Density — Count: {pred_map.sum():.1f}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Update: Evaluate dengan tambahan MNAE, PSNR, SSIM\n",
    "def evaluate_all_metrics(loader, model, device, max_batches=None):\n",
    "    mae_sum, mse_sum, mnae_sum = 0.0, 0.0, 0.0\n",
    "    psnr_list, ssim_list = [], []\n",
    "    n = 0\n",
    "\n",
    "    for i, (imgs, targets) in enumerate(tqdm(loader, desc='Evaluating')):\n",
    "        if max_batches is not None and i >= max_batches:\n",
    "            break\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(imgs)\n",
    "\n",
    "        pred_cnts = preds.sum(dim=(1,2,3)).cpu().numpy()\n",
    "        true_cnts = targets.sum(dim=(1,2)).cpu().numpy()\n",
    "\n",
    "        mae_sum  += np.abs(pred_cnts - true_cnts).sum()\n",
    "        mse_sum  += ((pred_cnts - true_cnts)**2).sum()\n",
    "        mnae_sum += (np.abs(pred_cnts - true_cnts) / (true_cnts + 1e-8)).sum()\n",
    "\n",
    "        for b in range(imgs.size(0)):\n",
    "            pred_map = preds[b].squeeze().cpu().numpy()\n",
    "            gt_map = targets[b].squeeze().cpu().numpy()\n",
    "            # Resize pred_map ke ukuran gt_map\n",
    "            pred_map_resized = cv2.resize(pred_map, (gt_map.shape[1], gt_map.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "            psnr_val = psnr(gt_map, pred_map_resized, data_range=gt_map.max() - gt_map.min())\n",
    "            ssim_val = ssim(gt_map, pred_map_resized, data_range=gt_map.max() - gt_map.min())\n",
    "            psnr_list.append(psnr_val)\n",
    "            ssim_list.append(ssim_val)\n",
    "\n",
    "        n += imgs.size(0)\n",
    "\n",
    "    mae  = mae_sum / n\n",
    "    rmse = np.sqrt(mse_sum / n)\n",
    "    mnae = mnae_sum / n\n",
    "    avg_psnr = np.mean(psnr_list)\n",
    "    avg_ssim = np.mean(ssim_list)\n",
    "\n",
    "    return mae, rmse, mnae, avg_psnr, avg_ssim\n",
    "\n",
    "mae, rmse, mnae, avg_psnr, avg_ssim = evaluate_all_metrics(train_loader, model, DEVICE, MAX_BATCHES)\n",
    "\n",
    "print(f\"\\n== Evaluation Metrics ==\")\n",
    "print(f\"MAE   : {mae:.3f}\")\n",
    "print(f\"RMSE  : {rmse:.3f}\")\n",
    "print(f\"MNAE  : {mnae:.3f}\")\n",
    "print(f\"PSNR  : {avg_psnr:.3f} dB\")\n",
    "print(f\"SSIM  : {avg_ssim:.4f}\")\n",
    "\n",
    "plot_density_examples(train_loader, model, DEVICE, PLOT_SAMPLES)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO8g/yiA83x0yLlrLB/nmzN",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
